# 2022 Lics 知识对话

## 1. 项目&任务介绍

一句话介绍（todo）

本次任务为[2022语言与智能技术竞赛：知识对话](https://aistudio.baidu.com/aistudio/competition/detail/158/0/task-definition)，**知识对话**是指对话系统利用外部知识信息，使聊天内容更加丰富、准确，这对提升用户体验是非常重要的，近年来受到学术界和工业界的广泛关注。

本次任务中，主要从以下两个子任务评测系统的知识对话能力：

- query生成任务

  给定多轮对话历史，生成用于查询搜索引擎的Query；

  • 输入：用户信息（M）、对话历史（H: u_1, b_1, u_2, b_2 …, u_t）
  • 输出：是否需要搜索知识 or 若需要则生成搜索问题（q_t）

- 对话回复任务

  给定文本知识与多轮对话历史，生成合适的对话回复。

  • 输入：用户信息（M）、搜索Query（q_t）、搜索知识（k）、对话历史（H: u_1, b_1, u_2, b_2 …, u_t）
  • 输出：符合对话历史，且自然流畅、信息丰富的机器回复b_t。

## 2. 数据介绍

本次官方提出一个全新的知识对话任务数据——搜索信息增强的对话(DuSinc)。

DuSinc数据集来自真实的人—人对话。在数据收集过程中，对话参与者，分别要求扮演USER和BOT。其中USER有自己的兴趣与所在地点，可作为聊天的话题；BOT在聊天中可以实时查询搜索引擎，与USER进行深入地对话交互。该数据集领域开放，包含广泛的对话话题，更多信息可以参考论文。

DuSinc数据集包含训练集、验证集、测试集A和测试集B。

**训练集**：2000个样本，每个样本均是多轮对话，其中每组对话不少于10句。BOT的对话中，包含是否使用了搜索引擎，以及查询的Query及利用的知识；

**验证集**：200个样本，数据构造方法和分布与训练集完全相同；

**测试集A**：1100个样本，数据构造方法和分布与训练集完全相同，其中350组为Query生成任务，750组为知识对话生成任务，当前排行榜所使用的数据；

**测试集B**：同测试集A，该测试集用于最后阶段判断选手进入复赛的依据。

每个样本数据为json格式，共包含三个key，分别为user_location（用户地点）、user_topical（用户兴趣）和conversation（对话序列），形如下，

```
{
	"user_location": "安徽 省 芜湖 市",   # 一个字符串
	"user_topical": ["泛 娱乐", "电视", ""],    # list，存在空字符串的元素 
	"conversation": [
				{"role": "user", "utterence": "我 最近 迷 上 了 综艺 ， 你 有 什么 好 的 节目 可以 推荐 给 我 吗 ？"},
				{"role": "bot", "utterence": "哦 ， 那 你 是 喜欢 看 真人 秀 、 推理 悬疑 ， 还是 选秀 呢 ？", 
				 "use_kg_label": "true",
         "use_knowledge": "随着 当今 电视 综艺 节目 的 流行 ， 综艺 节目 也 渐渐 扩展 出 多 个 类型 ， 如 晚会 、 生活 、 访谈 、 音乐 、 游戏 、 旅游 、 真人 秀 、 美食 、 选秀 、 益智 、 搞笑 、 纪实 、 曲艺 、 舞蹈 、 脱 口 秀 、 科技 等 。",
         "use_query": "综艺 分类",
         "other_search": [] },
         {"role": "user", "utterence": ...},
         {"role": "bot", "utterence": ...}
	]
}
```

| 标签          | 含义                               |
| :------------ | :--------------------------------- |
| conversation  | 包含多轮对话的列表                 |
| role          | 每一句话的角色（user or bot）      |
| utterance     | 对话内容                           |
| use_kg_label  | 对话回复是否使用了搜索知识         |
| use_query     | 搜索知识使用的query                |
| use_knowledge | 被使用的搜索知识                   |
| other_search  | 当前进行了搜索但没有使用的知识列表 |

## 3. 模型评估

上述两个子任务分别使用如下自动指标进行评测。
1）子任务1：query生成任务，共有三个评估指标，

- Q_ACC表示是否检索知识的二分类准确率；
- Q_F1表示数据集中需要检索时，预测Query与标准Query的字粒度匹配得分；
- Q_BLEU表示数据集中需要检索时，预测Query与标准Query的字粒度BLEU1/2值

2）子任务2：对话回复任务

- D_F1表示预测回复与标准回复的字粒度匹配打分；
- D_BLEU表示预测回复与标准回复的字粒度BLEU1/2值；
- D_DISTINCT1/2是对话内容多样性的自动指标

总分数的公式为：Score = 0.3 * (Q_ACC + Q_F1+ Q_BLEU1 + Q_BLEU2) + 0.7 * (D_F1+ D_BLEU1 + D_BLEU2)。

> Note：可以看出对话回复任务的重要度要更高些，其占比为70%


